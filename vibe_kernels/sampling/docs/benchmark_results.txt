
====================================================================================================
COMPREHENSIVE TOP-K BENCHMARK
Comparing: CuTe (ours) vs QuACK (original) vs Triton (ours) vs PyTorch
====================================================================================================

====================================================================================================
    M     N    k |    PyTorch |      CuTe(ours) |           QuACK |          Triton |       Best
                 |       (ms) |      (ms) Spdup |      (ms) Spdup |      (ms) Spdup |           
====================================================================================================
 4096    64    8 |   0.0291 |   0.1074  0.27x |   0.0963  0.30x |             N/A |    PyTorch
 4096    64   16 |   0.0293 |   0.1025  0.29x |   0.0996  0.29x |             N/A |    PyTorch
 4096    64   32 |   0.0286 |   0.1000  0.29x |   0.1012  0.28x |             N/A |    PyTorch
 4096   128    8 |   0.0434 |   0.0991  0.44x |   0.0978  0.44x |             N/A |    PyTorch
 4096   128   16 |   0.0443 |   0.1034  0.43x |   0.1122  0.40x |             N/A |    PyTorch
 4096   128   32 |   0.0452 |   0.1017  0.44x |   0.0981  0.46x |             N/A |    PyTorch
 4096   256    8 |   0.0749 |   0.0991  0.76x |   0.0977  0.77x |             N/A |    PyTorch
 4096   256   16 |   0.0755 |   0.0991  0.76x |   0.1008  0.75x |             N/A |    PyTorch
 4096   256   32 |   0.0773 |   0.0960  0.81x |   0.0987  0.78x |             N/A |    PyTorch
 4096   512    8 |   0.0959 |   0.0990  0.97x |   0.1042  0.92x |             N/A |    PyTorch
 4096   512   16 |   0.0962 |   0.1000  0.96x |   0.1053  0.91x |             N/A |    PyTorch
 4096   512   32 |   0.0972 |   0.1046  0.93x |   0.1053  0.92x |             N/A |    PyTorch
 4096  1024    8 |   0.1105 |   0.1015  1.09x |   0.1020  1.08x |             N/A | CuTe(ours)
 4096  1024   16 |   0.1109 |   0.1041  1.07x |   0.1059  1.05x |             N/A | CuTe(ours)
 4096  1024   32 |   0.1129 |   0.0995  1.14x |   0.0984  1.15x |             N/A |      QuACK
 4096  1024   64 |   0.1234 |   0.1003  1.23x |   0.0998  1.24x |             N/A |      QuACK
 4096  2048   32 |   0.1427 |   0.0989  1.44x |   0.1865  0.76x |             N/A | CuTe(ours)
 4096  2048   64 |   0.1561 |   0.0997  1.57x |   0.1009  1.55x |             N/A | CuTe(ours)
 4096  2048  128 |   0.1574 |   0.1000  1.57x |   0.1012  1.55x |             N/A | CuTe(ours)
 4096  4096   32 |   0.2290 |   0.1015  2.26x |   0.0984  2.33x |             N/A |      QuACK
 4096  4096   64 |   0.2427 |   0.1022  2.37x |   0.1015  2.39x |             N/A |      QuACK
 4096  4096  128 |   0.2490 |   0.1790  1.39x |   0.1733  1.44x |             N/A |      QuACK
====================================================================================================

====================================================================================================
SUMMARY STATISTICS
====================================================================================================

CuTe (ours) vs PyTorch:
  Min speedup:  0.27x
  Max speedup:  2.37x
  Mean speedup: 1.02x

QuACK (original) vs PyTorch:
  Min speedup:  0.28x
  Max speedup:  2.39x
  Mean speedup: 0.99x

CuTe (ours) vs QuACK (original):
  Min ratio:  0.90x
  Max ratio:  1.89x
  Mean ratio: 1.04x
  â†’ Our CuTe is faster than QuACK on average!

====================================================================================================
